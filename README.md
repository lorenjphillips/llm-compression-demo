# Kobi Compression: Regex-Based Slang & Abbreviation System

## ðŸš€ Getting Started: Development & Deployment

### 1. Prerequisites
- **Node.js** (v18+ recommended)
- **npm** or **bun** (for dependency management)

### 2. Clone the Repository
```bash
git clone https://github.com/your-username/coval-compression.git
cd coval-compression
```

### 3. Install Dependencies
#### For the frontend and backend (monorepo):
```bash
# Install root dependencies
npm install

# Install backend dependencies
cd backend
npm install
cd ..
```
*Or use `bun install` if you prefer bun.*

### 4. Environment Variables & API Keys
- Create a `.env` file in the root and/or `backend/` directory as needed.
- Example `.env` (adjust as required):
  ```env
  # For backend (if using external APIs)
  OPENAI_API_KEY=your_openai_key_here
  # Add other keys as needed
  ```
- **Note:** This project may not require API keys unless integrating with LLMs or external services.

### 5. Running in Development
#### Frontend:
```bash
npm run dev
# or
bun run dev
```

#### Backend:
```bash
cd backend
npm run dev
# or
bun run dev
```

### 6. Building for Production
#### Frontend:
```bash
npm run build
# or
bun run build
```

#### Backend:
```bash
cd backend
npm run build
# or
bun run build
```

### 7. Deployment

#### Vercel Deployment (Recommended)
This project is configured for Vercel deployment with serverless functions.

##### First-time Setup:
1. **Install Vercel CLI** (if not already installed):
   ```bash
   npm i -g vercel
   ```

2. **Login to Vercel**:
   ```bash
   vercel login
   ```

3. **Deploy with confirmation**:
   ```bash
   vercel --prod --yes
   ```

##### Environment Variables:
After deployment, you must configure the OpenAI API key:

1. Go to your Vercel project dashboard:
   - Visit: https://vercel.com/dashboard
   - Select your project (coval-compression)

2. Navigate to **Settings â†’ Environment Variables**

3. Add the following variable:
   - **Name**: `OPENAI_API_KEY`
   - **Value**: Your OpenAI API key (starts with `sk-`)

4. **Redeploy** after adding the environment variable:
   ```bash
   vercel --prod --yes
   ```

##### Local Development with Vercel:
```bash
# Start local development server with serverless functions
vercel dev
```

Make sure you have a `.env.local` file with your OpenAI API key:
```env
OPENAI_API_KEY=your_openai_key_here
```

#### Project Structure:
- Frontend: Built with Vite + React + TypeScript
- API Functions: `/api/chat.js` and `/api/tokenize.js` (serverless functions)
- Build Output: `dist/` directory
- Configuration: `vercel.json` handles build and function settings

---

# Text Compression Algorithm: Regex-Based Slang & Abbreviation System

## Overview
Create a text compression algorithm that uses regex patterns to transform standard English into compact texting/millennial slang while preserving semantic meaning for LLM comprehension. The goal is maximum size reduction with minimal information loss.

## Core Principles

### 1. Semantic Preservation
- Maintain sentence structure and grammar
- Preserve key information words (nouns, verbs, adjectives)
- Keep punctuation that affects meaning
- Ensure LLM can still parse intent and context

### 2. Compression Priorities (in order)
1. **Popular texting abbreviations** (u, ur, 2, 4, etc.)
2. **Vowel reduction** in non-critical words
3. **Common word substitutions** (and â†’ &, with â†’ w/, etc.)
4. **Number-letter substitutions** (to â†’ 2, for â†’ 4, ate â†’ 8)
5. **Contraction expansion** then re-compression

## Implementation Strategy

### Phase 1: Pre-processing
- Convert to lowercase (preserve proper nouns)
- Tokenize while preserving punctuation
- Identify word boundaries and sentence structure

### Phase 2: Primary Transformations (Regex Patterns)

#### A. Essential Word Replacements
```
you â†’ u
your â†’ ur  
you're â†’ ur
to â†’ 2
too â†’ 2
for â†’ 4
before â†’ b4
because â†’ bc
and â†’ &
with â†’ w/
without â†’ w/o
about â†’ abt
something â†’ smth
nothing â†’ nthn
```

#### B. Number-Letter Phonetic Substitutions
```
great â†’ gr8
late â†’ l8
wait â†’ w8
mate â†’ m8
create â†’ cr8
ate/eat â†’ 8
tonight â†’ 2nite
today â†’ 2day
tomorrow â†’ 2morrow
```

#### C. Common Abbreviations
```
probably â†’ prob
definitely â†’ def
obviously â†’ obv
literally â†’ lit
actually â†’ acc
seriously â†’ srsly
especially â†’ esp
```

#### D. Vowel Reduction (Secondary Priority)
```
Apply to words >4 letters:
- Remove vowels from middle of words
- Keep first and last letters
- Preserve double consonants
- Examples: between â†’ btwn, through â†’ thru
```

### Phase 3: Advanced Optimizations

#### A. Contraction Handling
- can't â†’ cant
- won't â†’ wont  
- shouldn't â†’ shldnt
- would've â†’ wldve

#### B. Article and Preposition Reduction
```
the â†’ th (in non-critical contexts)
this â†’ ths
that â†’ tht
from â†’ frm
them â†’ thm
```

#### C. Ending Simplifications
```
-ing â†’ -n (when unambiguous)
-tion â†’ -shn
-ed â†’ -d (when phonetically clear)
```

## Pattern Implementation Guidelines

### Regex Construction Rules
1. **Word boundary anchoring**: Use `\b` to ensure whole-word matches
2. **Case sensitivity**: Handle both cases or normalize first
3. **Context awareness**: Avoid replacements that create ambiguity
4. **Ordering matters**: Apply transformations in priority order

### Example Pattern Structure
```
# Replace "you" with "u" (word boundaries)
\byou\b â†’ u

# Replace "great" with "gr8" 
\bgreat\b â†’ gr8

# Vowel reduction for longer words
\b([bcdfghjklmnpqrstvwxyz])([aeiou])([bcdfghjklmnpqrstvwxyz]{2,})([aeiou])([bcdfghjklmnpqrstvwxyz])\b
â†’ $1$3$5
```

## Compression Dictionary Structure

### Primary Dictionary (Highest Impact)
- Single character replacements: youâ†’u, andâ†’&
- Number substitutions: toâ†’2, forâ†’4, greatâ†’gr8
- Common texting: becauseâ†’bc, withâ†’w/, aboutâ†’abt

### Secondary Dictionary (Moderate Impact)  
- Vowel reductions: betweenâ†’btwn, throughâ†’thru
- Abbreviations: probablyâ†’prob, definitelyâ†’def
- Contractions: can'tâ†’cant, won'tâ†’wont

### Tertiary Dictionary (Fine-tuning)
- Article reductions: theâ†’th (context-dependent)
- Ending modifications: -ingâ†’-n, -tionâ†’-shn

## Quality Assurance Measures

### Reversibility Testing
- Maintain reverse mapping dictionary
- Test decompression accuracy
- Verify LLM comprehension on samples

### Semantic Validation
- Compare LLM responses to compressed vs original text
- Measure information retention rates
- Test on various text types (formal, casual, technical)

### Compression Metrics
- Character reduction percentage
- Word count reduction
- Readability preservation score

## Implementation Workflow

1. **Build comprehensive regex pattern library**
2. **Create ordered transformation pipeline**
3. **Implement conflict resolution** (when multiple patterns match)
4. **Add context-awareness logic**
5. **Test and refine** with diverse text samples
6. **Optimize pattern ordering** for maximum compression

## New Level 4: Ultra Features ðŸš€

### Peak Millennial Slang
- **Internet classics**: omg, lol, rofl, btw, fr, ngl, tbh, imo, idk, wtf, smh
- **Gen Z favorites**: nocap, deds (deadass), nw (no worries), wtv (whatever)
- **Text shortcuts**: ttyl, cyl, gn, gm, gl, hf, hbd, grtz

### Extreme Number/Letter Substitutions
- **8-series**: ateâ†’8, eatâ†’8, str8, f8, d8, g8, h8, r8, st8, upd8, celebr8
- **1-series**: onceâ†’1ce, wonâ†’1, oneâ†’1, any1, sum1, every1, no1

### Aggressive Vowel Destruction
- **Smart vowel nuking**: Keeps first letter, essential consonants, last letter
- **Examples**: computerâ†’cmptr, internetâ†’intrnt, governmentâ†’gvrnmt
- **Multi-pattern vowel reduction** for maximum compression

### Enhanced Features
- **Proper noun preservation**: Protects names and important terms
- **Smart pattern ordering**: Prevents conflicts between rules
- **Readability scoring**: Balances compression vs. comprehension
- **Demo function**: Test all levels at once

## Compression Targets by Level

- **Level 1**: 10-15% reduction (conservative)
- **Level 2**: 20-30% reduction (balanced)
- **Level 3**: 35-50% reduction (aggressive)
- **Level 4**: 50-70%+ reduction (ULTRA ðŸ”¥)

## Expected Outcomes
- Up to 70%+ character reduction with Level 4 Ultra
- 10-60% word count reduction depending on level
- High LLM comprehension retention (>95%)
- Fast processing speed due to regex efficiency

## Special Considerations
- Preserve technical terms and proper nouns
- Handle edge cases (URLs, emails, code)
- Maintain readability for human verification
- Consider domain-specific abbreviations
- Plan for pattern updates and refinements 